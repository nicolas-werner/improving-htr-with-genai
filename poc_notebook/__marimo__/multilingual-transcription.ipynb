{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "# Multimodal Transcription of Medieval Handwriting: OpenAI vs Google Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Choose which AI model provider you want to use for transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<marimo-ui-element object-id='bkHC-0' random-id='2d13ea38-d3c9-1731-b19b-6c9ddb405391'><marimo-dropdown data-initial-value='[&quot;OpenAI&quot;]' data-label='&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Choose AI Model Provider&lt;/span&gt;&lt;/span&gt;&quot;' data-options='[&quot;OpenAI&quot;, &quot;Google Gemini&quot;]' data-allow-select-none='false' data-searchable='false' data-full-width='false'></marimo-dropdown></marimo-ui-element>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model selection\n",
    "model_provider = mo.ui.dropdown(\n",
    "    options=[\"OpenAI\", \"Google Gemini\"],\n",
    "    value=\"OpenAI\",\n",
    "    label=\"Choose AI Model Provider\"\n",
    ")\n",
    "\n",
    "model_provider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {},
   "source": [
    "## API Keys\n",
    "Enter your API keys for the selected model provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<marimo-ui-element object-id='PKri-1' random-id='9232ca2e-c139-4366-9216-2dd09617ac76'><marimo-text data-initial-value='&quot;&quot;' data-label='null' data-placeholder='&quot;GEMINI API KEY ...&quot;' data-kind='&quot;password&quot;' data-full-width='false' data-disabled='false' data-debounce='true'></marimo-text></marimo-ui-element>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OPENAI_API_KEY = mo.ui.text(placeholder=\"OPENAI API KEY ...\", kind=\"password\")\n",
    "GEMINI_API_KEY = mo.ui.text(placeholder=\"GEMINI API KEY ...\", kind=\"password\")\n",
    "\n",
    "# Display the appropriate API key input based on selected provider\n",
    "if model_provider.value == \"OpenAI\":\n",
    "    mo.output.replace(OPENAI_API_KEY)\n",
    "else:\n",
    "    mo.output.replace(GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "client = None\n",
    "\n",
    "# Initialize the appropriate client based on model provider\n",
    "if model_provider.value == \"OpenAI\" and OPENAI_API_KEY.value:\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY.value)\n",
    "elif model_provider.value == \"Google Gemini\" and GEMINI_API_KEY.value:\n",
    "    genai.configure(api_key=GEMINI_API_KEY.value)\n",
    "    client = genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt\n",
    "prompt_text = mo.ui.text_area(value=\"You are an expert for medieval handwritten middle high german. Transcribe the text in this image exactly and return it in markdown format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Upload\n",
    "file_upload = mo.ui.file(kind=\"area\", filetypes=[\".png\", \".jpg\", \".jpeg\"], multiple=False, label=\"Upload Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def encode_image_to_base64(image_file):\n",
    "    \"\"\"Utility function to encode image file to base64.\"\"\"\n",
    "    if image_file:\n",
    "        return base64.b64encode(image_file).decode(\"utf-8\")\n",
    "    return None\n",
    "\n",
    "def get_image_for_gemini(image_file):\n",
    "    \"\"\"Utility function to get image for Gemini API.\"\"\"\n",
    "    if image_file:\n",
    "        return Image.open(io.BytesIO(image_file))\n",
    "    return None\n",
    "\n",
    "# Handle image\n",
    "if file_upload.value:\n",
    "    base64_image = encode_image_to_base64(file_upload.value[0].contents)\n",
    "    pil_image = get_image_for_gemini(file_upload.value[0].contents)\n",
    "else:\n",
    "    base64_image = None\n",
    "    pil_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create state variables for outputs\n",
    "zero_shot_get, zero_shot_set = mo.state(\"\")\n",
    "one_shot_get, one_shot_set = mo.state(\"\")\n",
    "htr_get, htr_set = mo.state(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptionPage(BaseModel):\n",
    "    text: str = Field(..., description=\"The transcribed text of the page in Markdown.\")\n",
    "\n",
    "class TranscriptionError(BaseModel):\n",
    "    text: str = Field(..., description=\"Error message when transcription fails.\")\n",
    "    is_error: bool = Field(default=True, description=\"Flag indicating this is an error.\")\n",
    "\n",
    "def get_transcription(client, model_provider, system_prompt, content, response_format=None):\n",
    "    try:\n",
    "        if model_provider == \"OpenAI\":\n",
    "            completion = client.beta.chat.completions.parse(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": content}\n",
    "                ],\n",
    "                response_format=response_format,\n",
    "            )\n",
    "            return completion.choices[0].message.parsed\n",
    "\n",
    "        elif model_provider == \"Google Gemini\":\n",
    "            # Configure Gemini model\n",
    "            generation_config = {\n",
    "                \"temperature\": 0.1,\n",
    "                \"top_p\": 0.95,\n",
    "                \"response_mime_type\": \"text/plain\",\n",
    "            }\n",
    "\n",
    "            # Get Gemini model based on whether we're doing multimodal or text-only\n",
    "            model = client.GenerativeModel(\n",
    "                model_name=\"gemini-1.5-pro\",\n",
    "                generation_config=generation_config,\n",
    "            )\n",
    "\n",
    "            response = model.generate_content([\n",
    "                {\"role\": \"user\", \"parts\": [system_prompt]},\n",
    "                {\"role\": \"user\", \"parts\": content}\n",
    "            ])\n",
    "\n",
    "            # Return in TranscriptionPage format for consistent interface\n",
    "            return TranscriptionPage(text=response.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return an object with a text attribute for consistent interface\n",
    "        return TranscriptionError(text=f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_button = mo.ui.run_button(label=\"Run Transcription üèÉ \", kind=\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot = mo.vstack([\n",
    "    \"System Prompt\", prompt_text,\n",
    "    \"Image to transcribe\", file_upload,\n",
    "    run_button,\n",
    "    mo.md(zero_shot_get())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Zero-Shot Transcription\n",
    "zero_shot_result = None\n",
    "zero_shot_status = None\n",
    "zero_shot_api_messages = None\n",
    "zero_shot_api_content = None\n",
    "\n",
    "if run_button.value:\n",
    "    try:\n",
    "        if file_upload.value and client:\n",
    "            # Start the loading spinner\n",
    "            zero_shot_model_name = \"OpenAI GPT-4o\" if model_provider.value == \"OpenAI\" else \"Google Gemini 1.5 Pro\"\n",
    "            zero_shot_status = mo.status.spinner(\n",
    "                title=f\"Transcribing Image with {zero_shot_model_name}\",\n",
    "                subtitle=f\"Sending request to {model_provider.value}...\",\n",
    "            )\n",
    "\n",
    "            # Run the transcription\n",
    "            with zero_shot_status:\n",
    "                if model_provider.value == \"OpenAI\":\n",
    "                    zero_shot_api_messages = [\n",
    "                        {\"type\": \"text\", \"text\": \"Please transcribe this handwritten text:\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                    ]\n",
    "\n",
    "                    zero_shot_result = get_transcription(\n",
    "                        client=client,\n",
    "                        model_provider=model_provider.value,\n",
    "                        system_prompt=prompt_text.value,\n",
    "                        content=zero_shot_api_messages,\n",
    "                        response_format=TranscriptionPage\n",
    "                    )\n",
    "                else:  # Google Gemini\n",
    "                    zero_shot_api_content = [\n",
    "                        \"Please transcribe this handwritten text:\",\n",
    "                        pil_image\n",
    "                    ]\n",
    "\n",
    "                    zero_shot_result = get_transcription(\n",
    "                        client=client,\n",
    "                        model_provider=model_provider.value,\n",
    "                        system_prompt=prompt_text.value,\n",
    "                        content=zero_shot_api_content\n",
    "                    )\n",
    "\n",
    "            # Check if result is an error\n",
    "            if hasattr(zero_shot_result, 'is_error') and zero_shot_result.is_error:\n",
    "                zero_shot_set(f\"**Error**: {zero_shot_result.text}\")\n",
    "            else:\n",
    "                # Create the output using mo.hstack and convert to HTML string\n",
    "                zero_shot_output_content = mo.hstack(\n",
    "                    items=[\n",
    "                        mo.image(file_upload.value[0].contents), \n",
    "                        mo.md(f\"### Transcription ({model_provider.value}): \\n {zero_shot_result.text}\")\n",
    "                    ],\n",
    "                    widths=\"equal\",\n",
    "                    gap=1,\n",
    "                    align=\"start\",\n",
    "                    justify=\"center\"\n",
    "                )\n",
    "                zero_shot_set(zero_shot_output_content._repr_html_())\n",
    "        else:\n",
    "            if not file_upload.value:\n",
    "                zero_shot_set(\"**Please upload an image file first!**\")\n",
    "            elif not client:\n",
    "                zero_shot_set(f\"**Please enter a valid {model_provider.value} API key!**\")\n",
    "    except Exception as e:\n",
    "        zero_shot_set(f\"**Error**: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt for One Shot\n",
    "one_shot_prompt_text = mo.ui.text_area(value=\"You are an expert for medieval handwritten middle high german. Here is an example of a handwritten text and its transcription. Use this example to help you transcribe the new text. Transcribe the text in this image exactly and return it in markdown format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Image Upload\n",
    "example_file_upload = mo.ui.file(kind=\"area\", filetypes=[\".png\", \".jpg\", \".jpeg\"], multiple=False, label=\"Upload Example Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Transcription\n",
    "example_transcription = mo.ui.text_area(label=\"\", placeholder=\"Enter the correct transcription for the example image...\")\n",
    "\n",
    "if example_file_upload.value:\n",
    "    mo.output.replace(mo.md(\"**Example image uploaded successfully!**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Image Upload for One Shot\n",
    "one_shot_file_upload = mo.ui.file(kind=\"area\", filetypes=[\".png\", \".jpg\", \".jpeg\"], multiple=False, label=\"Upload Target Image to Transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "if one_shot_file_upload.value:\n",
    "    one_shot_base64_image = encode_image_to_base64(one_shot_file_upload.value[0].contents)\n",
    "    one_shot_pil_image = get_image_for_gemini(one_shot_file_upload.value[0].contents)\n",
    "    mo.output.replace(mo.md(\"**Target image uploaded successfully!**\"))\n",
    "else:\n",
    "    one_shot_base64_image = None\n",
    "    one_shot_pil_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "if example_file_upload.value:\n",
    "    example_base64_image = encode_image_to_base64(example_file_upload.value[0].contents)\n",
    "    example_pil_image = get_image_for_gemini(example_file_upload.value[0].contents)\n",
    "else:\n",
    "    example_base64_image = None\n",
    "    example_pil_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_run_button = mo.ui.run_button(label=\"Run One-Shot Transcription üèÉ \", kind=\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run One-Shot Transcription\n",
    "one_shot_result = None\n",
    "one_shot_status = None\n",
    "one_shot_api_messages = None\n",
    "one_shot_api_content = None\n",
    "\n",
    "if one_shot_run_button.value:\n",
    "    try:\n",
    "        if one_shot_file_upload.value and example_file_upload.value and example_transcription.value and client:\n",
    "            # Start the loading spinner\n",
    "            one_shot_model_name = \"OpenAI GPT-4o\" if model_provider.value == \"OpenAI\" else \"Google Gemini 1.5 Pro\"\n",
    "            one_shot_status = mo.status.spinner(\n",
    "                title=f\"Transcribing Image with One-Shot Learning using {one_shot_model_name}\",\n",
    "                subtitle=f\"Sending request to {model_provider.value}...\",\n",
    "            )\n",
    "\n",
    "            # Prepare the messages with example and target\n",
    "            with one_shot_status:\n",
    "                if model_provider.value == \"OpenAI\":\n",
    "                    one_shot_api_messages = [\n",
    "                        {\"type\": \"text\", \"text\": \"Here is an example of handwritten text:\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{example_base64_image}\"}},\n",
    "                        {\"type\": \"text\", \"text\": f\"The correct transcription is:\\n{example_transcription.value}\\n\\nNow please transcribe this new text:\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{one_shot_base64_image}\"}}\n",
    "                    ]\n",
    "\n",
    "                    one_shot_result = get_transcription(\n",
    "                        client=client,\n",
    "                        model_provider=model_provider.value,\n",
    "                        system_prompt=one_shot_prompt_text.value,\n",
    "                        content=one_shot_api_messages,\n",
    "                        response_format=TranscriptionPage\n",
    "                    )\n",
    "                else:  # Google Gemini\n",
    "                    one_shot_api_content = [\n",
    "                        f\"Here is an example of handwritten text:\",\n",
    "                        example_pil_image,\n",
    "                        f\"The correct transcription is:\\n{example_transcription.value}\\n\\nNow please transcribe this new text:\",\n",
    "                        one_shot_pil_image\n",
    "                    ]\n",
    "\n",
    "                    one_shot_result = get_transcription(\n",
    "                        client=client,\n",
    "                        model_provider=model_provider.value,\n",
    "                        system_prompt=one_shot_prompt_text.value,\n",
    "                        content=one_shot_api_content\n",
    "                    )\n",
    "\n",
    "            # Check if result is an error\n",
    "            if hasattr(one_shot_result, 'is_error') and one_shot_result.is_error:\n",
    "                one_shot_set(f\"**Error**: {one_shot_result.text}\")\n",
    "            else:\n",
    "                one_shot_output_content = mo.hstack(\n",
    "                    items=[\n",
    "                        mo.image(one_shot_file_upload.value[0].contents), \n",
    "                        mo.md(f\"### Transcription ({model_provider.value}): \\n {one_shot_result.text}\")\n",
    "                    ],\n",
    "                    widths=\"equal\",\n",
    "                    gap=1,\n",
    "                    align=\"start\",\n",
    "                    justify=\"center\"\n",
    "                )\n",
    "                one_shot_set(one_shot_output_content._repr_html_())\n",
    "        else:\n",
    "            one_shot_missing_items = []\n",
    "            if not example_file_upload.value:\n",
    "                one_shot_missing_items.append(\"example image\")\n",
    "            if not example_transcription.value:\n",
    "                one_shot_missing_items.append(\"example transcription\")\n",
    "            if not one_shot_file_upload.value:\n",
    "                one_shot_missing_items.append(\"target image\")\n",
    "            if not client:\n",
    "                one_shot_missing_items.append(f\"{model_provider.value} API key\")\n",
    "\n",
    "            one_shot_set(f\"**Missing required inputs: {', '.join(one_shot_missing_items)}**\")\n",
    "    except Exception as e:\n",
    "        one_shot_set(f\"**Error**: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot = mo.vstack([\n",
    "    \"System Prompt\", one_shot_prompt_text,\n",
    "    \"Example Image\", example_file_upload,\n",
    "    \"Example Transcription\", example_transcription,\n",
    "    \"Target Image to Transcribe\", one_shot_file_upload,\n",
    "    one_shot_run_button,\n",
    "    mo.md(one_shot_get())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt for HTR Improvement\n",
    "htr_prompt_text = mo.ui.text_area(value=\"You are an expert for medieval handwritten middle high german. I will provide you with an image of handwritten text and the output from a classical HTR (Handwritten Text Recognition) model. This output may contain errors. Your task is to correct any errors and provide an accurate transcription. Return the corrected text in markdown format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aLJB",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Upload for HTR Improvement\n",
    "htr_file_upload = mo.ui.file(kind=\"area\", filetypes=[\".png\", \".jpg\", \".jpeg\"], multiple=False, label=\"Upload Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHfw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the uploaded image\n",
    "if htr_file_upload.value:\n",
    "    htr_base64_image = encode_image_to_base64(htr_file_upload.value[0].contents)\n",
    "    htr_pil_image = get_image_for_gemini(htr_file_upload.value[0].contents)\n",
    "    mo.output.replace(mo.md(\"**Image uploaded successfully!**\"))\n",
    "else:\n",
    "    htr_base64_image = None\n",
    "    htr_pil_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXTn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTR Output\n",
    "htr_output = mo.ui.text_area(label=\"\", placeholder=\"Paste the output from your classical HTR model here...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AjVT",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run button for HTR Improvement\n",
    "htr_run_button = mo.ui.run_button(label=\"Run HTR Improvement üèÉ \", kind=\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pHFh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run HTR Improvement\n",
    "htr_result = None\n",
    "htr_status = None\n",
    "htr_api_messages = None\n",
    "htr_api_content = None\n",
    "\n",
    "if htr_run_button.value:\n",
    "    try:\n",
    "        if htr_file_upload.value and htr_output.value and client:\n",
    "            # Start the loading spinner\n",
    "            htr_model_name = \"OpenAI GPT-4o\" if model_provider.value == \"OpenAI\" else \"Google Gemini 1.5 Pro\"\n",
    "            htr_status = mo.status.spinner(\n",
    "                title=f\"Improving HTR Output with {htr_model_name}\",\n",
    "                subtitle=f\"Sending request to {model_provider.value}...\",\n",
    "            )\n",
    "\n",
    "            # Run the transcription improvement\n",
    "            with htr_status:\n",
    "                if model_provider.value == \"OpenAI\":\n",
    "                    htr_api_messages = [\n",
    "                        {\"type\": \"text\", \"text\": \"Here is a handwritten text image:\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{htr_base64_image}\"}},\n",
    "                        {\"type\": \"text\", \"text\": f\"The classical HTR model produced this output:\\n\\n```\\n{htr_output.value}\\n```\\n\\nPlease correct any errors and provide an accurate transcription.\"}\n",
    "                    ]\n",
    "\n",
    "                    htr_result = get_transcription(\n",
    "                        client=client,\n",
    "                        model_provider=model_provider.value,\n",
    "                        system_prompt=htr_prompt_text.value,\n",
    "                        content=htr_api_messages,\n",
    "                        response_format=TranscriptionPage\n",
    "                    )\n",
    "                else:  # Google Gemini\n",
    "                    htr_api_content = [\n",
    "                        \"Here is a handwritten text image:\",\n",
    "                        htr_pil_image,\n",
    "                        f\"The classical HTR model produced this output:\\n\\n```\\n{htr_output.value}\\n```\\n\\nPlease correct any errors and provide an accurate transcription.\"\n",
    "                    ]\n",
    "\n",
    "                    htr_result = get_transcription(\n",
    "                        client=client,\n",
    "                        model_provider=model_provider.value,\n",
    "                        system_prompt=htr_prompt_text.value,\n",
    "                        content=htr_api_content\n",
    "                    )\n",
    "\n",
    "            # Check if result is an error\n",
    "            if hasattr(htr_result, 'is_error') and htr_result.is_error:\n",
    "                htr_set(f\"**Error**: {htr_result.text}\")\n",
    "            else:\n",
    "                htr_output_content = mo.vstack([\n",
    "                    mo.hstack(\n",
    "                        items=[\n",
    "                            mo.image(htr_file_upload.value[0].contents),\n",
    "                            mo.vstack([\n",
    "                                mo.md(\"### Original HTR Output:\"),\n",
    "                                mo.md(f\"```\\n{htr_output.value}\\n```\")\n",
    "                            ])\n",
    "                        ],\n",
    "                        widths=\"equal\",\n",
    "                        gap=1,\n",
    "                        align=\"start\",\n",
    "                        justify=\"center\"\n",
    "                    ),\n",
    "                    mo.md(f\"### Improved Transcription ({model_provider.value}):\"),\n",
    "                    mo.md(f\"{htr_result.text}\")\n",
    "                ])\n",
    "                htr_set(htr_output_content._repr_html_())\n",
    "        else:\n",
    "            htr_missing_items = []\n",
    "            if not htr_file_upload.value:\n",
    "                htr_missing_items.append(\"image\")\n",
    "            if not htr_output.value:\n",
    "                htr_missing_items.append(\"HTR output\")\n",
    "            if not client:\n",
    "                htr_missing_items.append(f\"{model_provider.value} API key\")\n",
    "\n",
    "            htr_set(f\"**Missing required inputs: {', '.join(htr_missing_items)}**\")\n",
    "    except Exception as e:\n",
    "        htr_set(f\"**Error**: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NCOB",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the HTR improvement tab\n",
    "htr_improvement = mo.vstack([\n",
    "    \"System Prompt\", htr_prompt_text,\n",
    "    \"Image\", htr_file_upload,\n",
    "    \"Classical HTR Output\", htr_output,\n",
    "    htr_run_button,\n",
    "    mo.md(htr_get())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aqbW",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<marimo-ui-element object-id='aqbW-0' random-id='1c0a3d5a-8f8d-4a1a-0efb-18806375bdef'><marimo-tabs data-initial-value='&quot;&quot;' data-label='null' data-tabs='[&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Zero Shot&lt;/span&gt;&lt;/span&gt;&quot;, &quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;One Shot&lt;/span&gt;&lt;/span&gt;&quot;, &quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;HTR Improvement&lt;/span&gt;&lt;/span&gt;&quot;]'><div data-kind='tab'><div style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'><div><span>System Prompt</span></div><div><marimo-ui-element object-id='SFPL-0' random-id='5b9dbf9b-c240-2867-06e9-0b59d051a223'><marimo-text-area data-initial-value='&quot;You are an expert for medieval handwritten middle high german. Transcribe the text in this image exactly and return it in markdown format.&quot;' data-label='null' data-placeholder='&quot;&quot;' data-disabled='false' data-debounce='true' data-full-width='false'></marimo-text-area></marimo-ui-element></div><div><span>Image to transcribe</span></div><div><marimo-ui-element object-id='BYtC-0' random-id='b0e0300d-fd26-83fd-53ba-8e3b9137b3ad'><marimo-file data-initial-value='[]' data-label='&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Upload Image&lt;/span&gt;&lt;/span&gt;&quot;' data-filetypes='[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;]' data-multiple='false' data-kind='&quot;area&quot;'></marimo-file></marimo-ui-element></div><div><marimo-ui-element object-id='Hstk-0' random-id='aa1cf20a-da71-cb8a-33fe-0e89d81dc8c8'><marimo-button data-initial-value='0' data-label='&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Run Transcription &#92;ud83c&#92;udfc3 &lt;/span&gt;&lt;/span&gt;&quot;' data-kind='&quot;success&quot;' data-disabled='false' data-full-width='false'></marimo-button></marimo-ui-element></div><div><span class=\"markdown prose dark:prose-invert\"><div style='display: flex;flex: 1;flex-direction: row;justify-content: center;align-items: flex-start;flex-wrap: nowrap;gap: 1rem'><div style='flex: 1'><img src='./@file/1940870-678882-jwYFabHb.png' /></div><div style='flex: 1'><span class=\"markdown prose dark:prose-invert\"><h3 id=\"transcription-google-gemini\">Transcription (Google Gemini):</h3>\n",
       "<span class=\"paragraph\"><strong>Der wurcze Suck</strong></span>\n",
       "<span class=\"paragraph\">The text is arranged in a circular pattern around a drawing of a sack.  Each segment is divided by lines, and the text alternates in color between reddish-brown and dark brown/black.  Here's a transcription attempting to follow the clockwise order, starting from the top:</span>\n",
       "<ul>\n",
       "<li><strong>Duckwen</strong></li>\n",
       "<li><strong>Amgdaly</strong> (likely <em>Amygdaly</em>)</li>\n",
       "<li><strong>Ciminum</strong> (likely <em>Cyminum</em>)</li>\n",
       "<li><strong>Orzagati</strong> (likely <em>Ortzagati</em>)</li>\n",
       "<li><strong>Balpoms</strong></li>\n",
       "<li><strong>Pipex</strong></li>\n",
       "<li><strong>Zedanum</strong></li>\n",
       "<li><strong>Smabex</strong></li>\n",
       "<li><strong>Daulum</strong></li>\n",
       "<li><strong>Yogamem</strong> (likely <em>Gogamem</em>)</li>\n",
       "<li><strong>Croare</strong></li>\n",
       "<li><strong>Ambra</strong></li>\n",
       "<li><strong>Bartolomeu</strong></li>\n",
       "<li><strong>Pohannem</strong> (likely <em>Johannem</em>)</li>\n",
       "<li><strong>Phelipen</strong> (likely <em>Philippen</em>)</li>\n",
       "<li><strong>Matiam</strong></li>\n",
       "</ul>\n",
       "<span class=\"paragraph\">Within each segment, there are additional words, often appearing smaller and sometimes harder to decipher.  These seem to relate to weights, measures, or pricing.  A tentative transcription of these inner words, following the same clockwise order as above, is as follows:</span>\n",
       "<ul>\n",
       "<li><em>Buch</em></li>\n",
       "<li><em>Buch zer</em></li>\n",
       "<li><em>Buch zu</em></li>\n",
       "<li><em>Matiam in</em></li>\n",
       "<li><em>Buch in</em></li>\n",
       "<li><em>Buch in</em></li>\n",
       "<li><em>Buch in</em></li>\n",
       "<li><em>Buch in</em></li>\n",
       "<li><em>Buch</em></li>\n",
       "<li><em>Buch zu amos</em></li>\n",
       "<li><em>paulum</em></li>\n",
       "<li><em>Suage zer</em></li>\n",
       "<li><em>Buch</em></li>\n",
       "<li><em>Buch in amos</em></li>\n",
       "<li><em>Buch zer</em></li>\n",
       "<li><em>Buch in</em></li>\n",
       "</ul>\n",
       "<span class=\"paragraph\">It's important to note that this transcription is based on a visual interpretation and the paleography of Middle High German. Some words might have alternative readings depending on the specific dialect and context.  The abbreviations and ligatures common in medieval manuscripts also add to the complexity of transcription.</span></span></div></div></span></div></div></div><div data-kind='tab'><div style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'><div><span>System Prompt</span></div><div><marimo-ui-element object-id='ZHCJ-0' random-id='768c3155-1a67-1c91-4bcf-bf20af509b4d'><marimo-text-area data-initial-value='&quot;You are an expert for medieval handwritten middle high german. Here is an example of a handwritten text and its transcription. Use this example to help you transcribe the new text. Transcribe the text in this image exactly and return it in markdown format.&quot;' data-label='null' data-placeholder='&quot;&quot;' data-disabled='false' data-debounce='true' data-full-width='false'></marimo-text-area></marimo-ui-element></div><div><span>Example Image</span></div><div><marimo-ui-element object-id='ROlb-0' random-id='fc25546e-819a-db50-aba6-ed31ddf4e42d'><marimo-file data-initial-value='[]' data-label='&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Upload Example Image&lt;/span&gt;&lt;/span&gt;&quot;' data-filetypes='[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;]' data-multiple='false' data-kind='&quot;area&quot;'></marimo-file></marimo-ui-element></div><div><span>Example Transcription</span></div><div><marimo-ui-element object-id='qnkX-0' random-id='37c5eec5-55d4-4e93-c4d8-d3dd573b3f96'><marimo-text-area data-initial-value='&quot;&quot;' data-label='null' data-placeholder='&quot;Enter the correct transcription for the example image...&quot;' data-disabled='false' data-debounce='true' data-full-width='false'></marimo-text-area></marimo-ui-element></div><div><span>Target Image to Transcribe</span></div><div><marimo-ui-element object-id='TqIu-0' random-id='daed4ea9-1878-6ff5-d2ed-0fdf400e235e'><marimo-file data-initial-value='[]' data-label='&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Upload Target Image to Transcribe&lt;/span&gt;&lt;/span&gt;&quot;' data-filetypes='[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;]' data-multiple='false' data-kind='&quot;area&quot;'></marimo-file></marimo-ui-element></div><div><marimo-ui-element object-id='ulZA-0' random-id='01276c4c-5813-9019-6676-04932c63585f'><marimo-button data-initial-value='0' data-label='&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Run One-Shot Transcription &#92;ud83c&#92;udfc3 &lt;/span&gt;&lt;/span&gt;&quot;' data-kind='&quot;success&quot;' data-disabled='false' data-full-width='false'></marimo-button></marimo-ui-element></div><div><span class=\"markdown prose dark:prose-invert\"></span></div></div></div><div data-kind='tab'><div style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'><div><span>System Prompt</span></div><div><marimo-ui-element object-id='ZBYS-0' random-id='0753b9b7-920c-7f24-330f-076cc86531cf'><marimo-text-area data-initial-value='&quot;You are an expert for medieval handwritten middle high german. I will provide you with an image of handwritten text and the output from a classical HTR (Handwritten Text Recognition) model. This output may contain errors. Your task is to correct any errors and provide an accurate transcription. Return the corrected text in markdown format.&quot;' data-label='null' data-placeholder='&quot;&quot;' data-disabled='false' data-debounce='true' data-full-width='false'></marimo-text-area></marimo-ui-element></div><div><span>Image</span></div><div><marimo-ui-element object-id='aLJB-0' random-id='1e582771-6073-2bb1-8176-bc632f5aaffe'><marimo-file data-initial-value='[]' data-label='&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Upload Image&lt;/span&gt;&lt;/span&gt;&quot;' data-filetypes='[&quot;.png&quot;, &quot;.jpg&quot;, &quot;.jpeg&quot;]' data-multiple='false' data-kind='&quot;area&quot;'></marimo-file></marimo-ui-element></div><div><span>Classical HTR Output</span></div><div><marimo-ui-element object-id='xXTn-0' random-id='9c9c5636-e47d-21d8-4949-d4fbc3b6c98b'><marimo-text-area data-initial-value='&quot;&quot;' data-label='null' data-placeholder='&quot;Paste the output from your classical HTR model here...&quot;' data-disabled='false' data-debounce='true' data-full-width='false'></marimo-text-area></marimo-ui-element></div><div><marimo-ui-element object-id='AjVT-0' random-id='74d8324c-f2e7-33fc-e6a7-7171c7332381'><marimo-button data-initial-value='0' data-label='&quot;&lt;span class=&#92;&quot;markdown prose dark:prose-invert&#92;&quot;&gt;&lt;span class=&#92;&quot;paragraph&#92;&quot;&gt;Run HTR Improvement &#92;ud83c&#92;udfc3 &lt;/span&gt;&lt;/span&gt;&quot;' data-kind='&quot;success&quot;' data-disabled='false' data-full-width='false'></marimo-button></marimo-ui-element></div><div><span class=\"markdown prose dark:prose-invert\"></span></div></div></div></marimo-tabs></marimo-ui-element>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the tabbed interface\n",
    "tabs = mo.ui.tabs({\n",
    "    \"Zero Shot\": zero_shot, \n",
    "    \"One Shot\": one_shot,\n",
    "    \"HTR Improvement\": htr_improvement\n",
    "})\n",
    "tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TRpd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"markdown prose dark:prose-invert\"><span class=\"paragraph\"><strong>Currently using: Google Gemini (Gemini 1.5 Pro)</strong></span></span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show which model provider is selected\n",
    "provider_name = model_provider.value\n",
    "model_name = \"GPT-4o\" if provider_name == \"OpenAI\" else \"Gemini 1.5 Pro\"\n",
    "\n",
    "mo.md(f\"**Currently using: {provider_name} ({model_name})**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TXez",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
